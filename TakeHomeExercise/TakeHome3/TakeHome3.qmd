---
title: "Take Home Exercise 3"
author: "Joshua TING"
date: "21 October, 2024"
date-modified: "last-modified"
format:
  html:
    code-fold: true
    code-summary: "Code Chunk"
    number-sections: true
execute:
  eval: false #r will run through all codes
  echo: true #r will display all code chunk
  warning: false #for mark down
  freeze: true #r will not render all existing  html files
  message: false #avoid printing warning message
editor: source
---

```{r}
pacman::p_load(tidyverse, sf, httr, jsonlite, rvest)
```

```{r}
resale <- read_csv("data/rawdata/resale.csv") %>%
  filter(month >= "2023-01" & month <= "2024-09")
```

```{r}
resale_tidy <- resale %>%
  mutate(address = paste(block,street_name)) %>% #combined block & street name
  mutate(remaining_lease_yr = as.integer(
    str_sub(remaining_lease, 0, 2)))%>% #extract remaining lease by yr
  mutate(remaining_lease_mth = as.integer(
    str_sub(remaining_lease, 9, 11))) #extract remaining lease by month
```

```{r}
resale_selected <- resale_tidy %>%
  filter(month == "2024-09")
```

```{r}
add_list <- sort(unique(resale_selected$address)) #parse a list as API cannot read df
#unique reduces records to pass to portal
#sort is used to easier to find geo codes
```

```{r}
get_coords <- function(add_list){
  
  # Create a data frame to store all retrieved coordinates
  postal_coords <- data.frame()
    
  for (i in add_list){
    #print(i)

    r <- GET('https://www.onemap.gov.sg/api/common/elastic/search?',
           query=list(searchVal=i,
                     returnGeom='Y',
                     getAddrDetails='Y'))
    data <- fromJSON(rawToChar(r$content))
    found <- data$found
    res <- data$results
    
    # Create a new data frame for each address
    new_row <- data.frame()
    
    # If single result, append 
    if (found == 1){
      postal <- res$POSTAL 
      lat <- res$LATITUDE
      lng <- res$LONGITUDE
      new_row <- data.frame(address= i, 
                            postal = postal, 
                            latitude = lat, 
                            longitude = lng)
    }
    
    # If multiple results, drop NIL and append top 1
    else if (found > 1){
      # Remove those with NIL as postal
      res_sub <- res[res$POSTAL != "NIL", ]
      
      # Set as NA first if no Postal
      if (nrow(res_sub) == 0) {
          new_row <- data.frame(address= i, 
                                postal = NA, 
                                latitude = NA, 
                                longitude = NA)
      }
      
      else{
        top1 <- head(res_sub, n = 1)
        postal <- top1$POSTAL 
        lat <- top1$LATITUDE
        lng <- top1$LONGITUDE
        new_row <- data.frame(address= i, 
                              postal = postal, 
                              latitude = lat, 
                              longitude = lng)
      }
    }

    else {
      new_row <- data.frame(address= i, 
                            postal = NA, 
                            latitude = NA, 
                            longitude = NA)
    }
    
    # Add the row
    postal_coords <- rbind(postal_coords, new_row)
  }
  return(postal_coords)
}
```

```{r}
coords <- get_coords(add_list)
```

```{r}
write_rds(coords, "data/rds/coords.rds")
```

```{r}
glimpse(coords)
```

::: callout-caution
## Postal Code in chr field

Otherwise if it in num field, the 0 will be truncated.
:::

Predictive looks into RMSE instead of R\^2 value. If building explanatory model, model and R\^2 is more important,

HDB data should use stratified sampling as every town is different in places. As spatial data, we need to be more sensitive in sampling. Eg: 25% of the hdb data comes from the tampines thus when you strafied it, you only choose 25% from tampines not 35%. NEED TO DEFINE YOUR OWN STRATA.

July - Sept (last 3 months) use as test data for take home exercise 3 and see how time will affect. Test data is something we intentionally retain it.

gwRF 1. first determinine bandwidth

```{r}
pacman::p_load()
```

```{r}
resale <- read_csv("")
```

need X Y coordinates

use LTA datamall:

```{r}
train_data_ngeom <- train_data %>%
  st_drop_geometry()

#need to drop sf data because ML spatial cannot read sf, noly numbers
```
